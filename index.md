---
layout: home
title: Home
enable_shit: true
---
<img style="float: right;" src="/funnyhat.jpg" border="2" width="40%">

In 2016, I graduated with a degree in Computer Engineering from Michigan Technological University after years of [robotics research](https://scholar.google.com/citations?user=E0nbCrYAAAAJ&hl=en), internships, and spending time [in nature](https://www.google.com/maps/place/Michigan+Technological+University/@47.0892921,-88.6100291,11.82z/data=!4m5!3m4!1s0x4d50c810d2807581:0x80d7ca9457d61ad5!8m2!3d47.1150259!4d-88.5452004)! Since then I've been working as a perception engineer and researcher by changing the way that robots see the world.

Since my work is mainly focused around building algorithms for new and exciting sensors, I'll showcase that here.

## Lidar
While in college, I developed a data-collection system which used a Hokuyo lidar like [this one](https://acroname.com/store/lidar-scanner-r314-hokuyo-laser4?gclid=EAIaIQobChMIyZGAsYvr-QIVRjizAB2pqQy3EAQYBiABEgL4LfD_BwE) which was designed to be mounted on a drone. It was used to map bridges in the Metro-Detroit Area like [this one](https://mtri.org/mdot_uav.html) under the guidance of [Dr. Timothy C. Havens](https://www.mtu.edu/cs/department/people/faculty/havens/).


Continuing that work, I added a camera to the same data collection system in order to develop a novel [camera-lidar](https://asmedigitalcollection.asme.org/dynamicsystems/article-abstract/139/7/071002/395297/Heterogeneous-Multisensor-Fusion-for-Mobile) sensor fusion system for pose estimation.


I continued my mapping work at Argo AI by [patenting](https://patents.google.com/patent/US11164369B2/en) a method to develop cm-level precision ground height maps using Gaussian Processes.


While still at Argo, I spent a significant amount of my time helping develop firmware and novel algorithms for their custom [Geiger-Mode](https://www.argo.ai/company-news/breakthrough-new-lidar-technology-gives-argo-ai-the-edge-in-autonomous-delivery-and-ride-hail-services/) lidar. Also being one of the original members of the team, I shipped their original deep-lidar based object detector which was deployed in five different cities.

## Stereo
While at Argo, I also pushed the state-of-the-art in field of stereo depth estimation by developing a [novel approach](https://scholar.google.com/citations?view_op=view_citation&hl=en&user=E0nbCrYAAAAJ&citation_for_view=E0nbCrYAAAAJ:u5HHmVD_uO8C) for deep stereo vision on high-resolution images in real-time.


## Radar
At Waymo, I use our incredible [imaging radar](https://www.forbes.com/sites/bradtempleton/2021/11/15/waymos-new-imaging-radar-takes-them-through-san-francisco-fog/?sh=d07c3602937f) to build deep radar algorithms for object detection. I also shipped several versions of these models directly onto our [autonomous truck](https://blog.waymo.com/2021/12/designed-to-deliver.html).

## In General...
Although I've had many other jobs and wonderful experiences throughout my career, I now consider myself to be a robotics engineer with a specialization in building machine learning algorithms for novel sensors. I'm always happy to chat about anything! If you want to learn more about me please use one of the links below, or just check out my [CV](/ManelaCV.pdf) for more information.
